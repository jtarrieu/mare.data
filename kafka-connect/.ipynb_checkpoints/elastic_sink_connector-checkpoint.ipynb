{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073dc8af-884e-4cb0-9af4-6003bb539abb",
   "metadata": {},
   "source": [
    "# Elastic sink connector\n",
    "\n",
    "sources:\n",
    "- https://docs.confluent.io/platform/current/connect/references/restapi.html\n",
    "\n",
    "This notebook explain how to connect an elasticsearch **index** to a Kafka **topic**.\n",
    "\n",
    "Pre-requisites:\n",
    "- elasticsearch, kafka(-connect) up and running\n",
    "- elastic-sink-connector.jar downloaded inside the **project/connectors** directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b37c7-c608-4a77-9fbd-87d0b4738cbf",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We want to communicate and send json to the kafka-connect container via its REST API. We nee **requests** and **json** modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6eac55e-b376-4682-ab7e-90ea5ae9c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "connect_url = \"http://kafka-connect:8083\"  # URL to your Kafka Connect REST API\n",
    "# headers for the http requests\n",
    "headers = {\"Content-Type\": \"application/json; charset=utf-8\",\n",
    "           \"Accept\": \"application/json\"\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab0d88-290b-47fe-9270-bcaea4616774",
   "metadata": {},
   "source": [
    "## List connectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c048ee3a-70f8-48a0-8292-0f27ef5f0c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of the connectors: [].\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "connect_url = \"http://kafka-connect:8083\"  # URL to your Kafka Connect REST API\n",
    "# headers for the http requests\n",
    "headers = {\"Content-Type\": \"application/json; charset=utf-8\",\n",
    "           \"Accept\": \"application/json\"\n",
    "          }\n",
    "# request\n",
    "response = requests.get(f'{connect_url}/connectors', headers=headers)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    print(f\"List of the connectors: {response.text}.\")\n",
    "else:\n",
    "    print(f\"Failed to list connectors: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61d051-2f57-4c91-bbea-e82c4069936d",
   "metadata": {},
   "source": [
    "## Connector configuration\n",
    "\n",
    "We need to write the specifications of the connection between the **topic** and the **index**.\n",
    "\n",
    "You can link multiple topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4144e396-b3e3-4bcb-ba7d-d493adeaaae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a name for the connector:  meteo\n",
      "Enter the topic names (separated by a comma):  meteo\n",
      "Enter the index name:  meteo\n"
     ]
    }
   ],
   "source": [
    "connector_name = input('Enter a name for the connector: ')\n",
    "topic_name = input('Enter the topic names (separated by a comma): ')\n",
    "index_name = input('Enter the index name: ')\n",
    "\n",
    "connector_config ={\n",
    "  \"name\": connector_name, # name of the connector\n",
    "  \"config\": {\n",
    "    \"connector.class\": \"io.confluent.connect.elasticsearch.ElasticsearchSinkConnector\", # choose your connector\n",
    "    \"tasks.max\": \"1\",  # max number of tasks at the same time\n",
    "    \"topics\": topic_name, # names of the topics \"topic-1, topic-2, ...\"\n",
    "    \"key.ignore\": \"true\", # should it take the key in consideration or not\n",
    "    \"schema.ignore\": \"true\", # should it ignore the schema ?\n",
    "    \"connection.url\": \"http://elasticsearch:9200\", # url of the elasticsearch service\n",
    "    \"type.name\": \"_doc\", # the identifier to search for a document ex /my-index/_doc/id\n",
    "    \"value.converter\": \"org.apache.kafka.connect.json.JsonConverter\",\n",
    "    \"value.converter.schemas.enable\": \"false\",\n",
    "    \"index.name\": index_name\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfca27ef-2170-4da5-ab35-1e1aba4bd3fe",
   "metadata": {},
   "source": [
    "## Create an index\n",
    "It is important to set a mapping inside elasticsearch order to have the timestamp and geopoint available inside our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c292b90-52ec-4ae8-804b-09c04f22b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "index name:  meteo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to create index. Status code: 400, Response: {\"error\":{\"root_cause\":[{\"type\":\"mapper_parsing_exception\",\"reason\":\"Root mapping definition has unsupported parameters:  [mappings : {properties={sensor_id={type=integer}, temperature={type=float}, humidity={type=float}, location={type=geo_point}, pressure={type=float}, timestamp={format=yyyy-MM-dd HH:mm:ss.SSSSSS, type=date}}}]\"}],\"type\":\"mapper_parsing_exception\",\"reason\":\"Failed to parse mapping: Root mapping definition has unsupported parameters:  [mappings : {properties={sensor_id={type=integer}, temperature={type=float}, humidity={type=float}, location={type=geo_point}, pressure={type=float}, timestamp={format=yyyy-MM-dd HH:mm:ss.SSSSSS, type=date}}}]\",\"caused_by\":{\"type\":\"mapper_parsing_exception\",\"reason\":\"Root mapping definition has unsupported parameters:  [mappings : {properties={sensor_id={type=integer}, temperature={type=float}, humidity={type=float}, location={type=geo_point}, pressure={type=float}, timestamp={format=yyyy-MM-dd HH:mm:ss.SSSSSS, type=date}}}]\"}},\"status\":400}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your Elasticsearch host and port\n",
    "es_host = 'http://elasticsearch:9200'\n",
    "\n",
    "# Replace with your desired index name\n",
    "index_name = input('index name: ')\n",
    "\n",
    "# Define the index mapping\n",
    "index_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"timestamp\": {\n",
    "                \"type\": \"date\",\n",
    "                \"format\": \"yyyy-MM-dd HH:mm:ss.SSSSSS\"\n",
    "            },\n",
    "            \"temperature\": {\n",
    "                \"type\": \"float\"\n",
    "            },\n",
    "            \"humidity\": {\n",
    "                \"type\": \"float\"\n",
    "            },\n",
    "            \"pressure\": {\n",
    "                \"type\": \"float\"\n",
    "            },\n",
    "            \"sensor_id\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"location\": {\n",
    "                \"type\": \"geo_point\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the index with mapping\n",
    "index_url = f\"{es_host}/{index_name}\"\n",
    "response = requests.put(index_url, json=index_mapping)\n",
    "\n",
    "# Check the response status\n",
    "if response.status_code == 200:\n",
    "    print(f\"Index '{index_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to create index. Status code: {response.status_code}, Response: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473c905-9ea5-41d2-aae8-8ccfa4a3f6ee",
   "metadata": {},
   "source": [
    "## Create the connector\n",
    "You should first create an  index with a correct mapping.\n",
    "Let's inject the configuration dict to kafka-connect via a http **POST** requests at the **/connectors/** level to connect the **topic** and the **index**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09541f2a-a1e8-4998-aeb2-8ec0cd8e7722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connector 'meteo' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create the connector\n",
    "response = requests.post(f\"{connect_url}/connectors/\",\n",
    "                         headers=headers,\n",
    "                         data=json.dumps(connector_config))\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 201:\n",
    "    print(f\"Connector '{connector_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to create connector: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afc7aae-ad03-4442-8bc2-c7e676184c88",
   "metadata": {},
   "source": [
    "## Describe a connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11467194-c2e9-4fb7-a88d-808ffaca0e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of the connector:  meteo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description meteo: {\"name\":\"meteo\",\"config\":{\"connector.class\":\"io.confluent.connect.elasticsearch.ElasticsearchSinkConnector\",\"type.name\":\"_doc\",\"index.name\":\"meteo\",\"tasks.max\":\"1\",\"topics\":\"meteo\",\"value.converter.schemas.enable\":\"false\",\"name\":\"meteo\",\"key.ignore\":\"true\",\"connection.url\":\"http://elasticsearch:9200\",\"value.converter\":\"org.apache.kafka.connect.json.JsonConverter\",\"schema.ignore\":\"true\"},\"tasks\":[{\"connector\":\"meteo\",\"task\":0}],\"type\":\"sink\"}.\n"
     ]
    }
   ],
   "source": [
    "# asking for a connector name\n",
    "connector_name = input('Enter the name of the connector: ')\n",
    "\n",
    "# request\n",
    "response = requests.get(f'{connect_url}/connectors/{connector_name}', headers=headers)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    print(f\"Description {connector_name}: {response.text}.\")\n",
    "else:\n",
    "    print(f\"Failed to list connectors: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cfd351-cee3-4ce5-b34b-b47ed6a4f956",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Delete a connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a50bfaa-ec2d-4e42-bb6e-4578a908c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of the connector:  meteo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connector meteo deleted.\n"
     ]
    }
   ],
   "source": [
    "# asking for a connector name\n",
    "connector_name = input('Enter the name of the connector: ')\n",
    "\n",
    "# request\n",
    "response = requests.delete(f'{connect_url}/connectors/{connector_name}', headers=headers)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 204:\n",
    "    print(f\"Connector {connector_name} deleted.\")\n",
    "else:\n",
    "    print(f\"Failed to delete connector: {response.status_code} - {response.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
