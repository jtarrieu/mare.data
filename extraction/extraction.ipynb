{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from MariaDB and save it in ndjson files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mariadb # librairie pour se connecter à mariadb\n",
    "import sys\n",
    "from extraction import var # import variable configured into var.py\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to MariaDB Platform\n",
    "try:\n",
    "    conn = mariadb.connect(\n",
    "        user=var.user,\n",
    "        password=var.password,\n",
    "        host=var.host,\n",
    "        port=3307,\n",
    "    )\n",
    "except mariadb.Error as e:\n",
    "    print(f\"Error connecting to MariaDB Platform: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Get Cursor\n",
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve databases on the server\n",
    "❗❗<code>SHOW DATABASES</code> query requires specific right on mariadb server\n",
    "If our user do not get those rights, please run the command with another user\n",
    "Some databases are not supposed to be transfered into Elastic, for exemple : <code>{'information_schema','mysql','sys','performance_schema'}</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SHOW DATABASES;\") #* require specific rights on mariadb server\n",
    "\n",
    "result = cur.fetchall() # retrieve all the results\n",
    "\n",
    "cur.close()\n",
    "# Create a list of databases name on the server\n",
    "dbs_list= []\n",
    "for row in result:\n",
    "    dbs_list.append(row[0]) \n",
    "\n",
    "#! TODO : complete unwanted_db with any database that should not be transfered into Elastic\n",
    "unwanted_db = {'information_schema','mysql','sys','performance_schema'}\n",
    "\n",
    "#* dbs_list contain all databases that will be taken into account for batch\n",
    "dbs_list = [db for db in dbs_list if db not in unwanted_db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meteo1', 'mouleconnected']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tables inside Databases\n",
    "We create a dictionnary <code>dict_db</code> with database name as key and value being a list  of tables inside the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each db we want to transfer, we store tables names in the dictionnary\n",
    "dict_db = {}\n",
    "for db in dbs_list:\n",
    "    cur = conn.cursor()\n",
    "    query = f\"SHOW TABLES FROM {db}\"\n",
    "    cur.execute(query)\n",
    "    result = cur.fetchall()\n",
    "    result = [value[0] for value in result] # keep only the name of the table\n",
    "    dict_db[db] = result\n",
    "    cur.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meteo1': ['DATA',\n",
       "  'LOGBOOK',\n",
       "  'ane0',\n",
       "  'bar0',\n",
       "  'cpr0',\n",
       "  'gps0',\n",
       "  'gsm0',\n",
       "  'ntp0',\n",
       "  'rad0',\n",
       "  'the0'],\n",
       " 'mouleconnected': ['Temperature',\n",
       "  'bac',\n",
       "  'capteur',\n",
       "  'data',\n",
       "  'data2',\n",
       "  'lumiere',\n",
       "  'moule',\n",
       "  'users']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dict_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dict of list into dict of dict with list for values extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meteo1': {'DATA': {},\n",
       "  'LOGBOOK': {},\n",
       "  'ane0': {},\n",
       "  'bar0': {},\n",
       "  'cpr0': {},\n",
       "  'gps0': {},\n",
       "  'gsm0': {},\n",
       "  'ntp0': {},\n",
       "  'rad0': {},\n",
       "  'the0': {}},\n",
       " 'mouleconnected': {'Temperature': {},\n",
       "  'bac': {},\n",
       "  'capteur': {},\n",
       "  'data': {},\n",
       "  'data2': {},\n",
       "  'lumiere': {},\n",
       "  'moule': {},\n",
       "  'users': {}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_db_tables = {}\n",
    "for key, values in dict_db.items():\n",
    "    dict_db_tables[key] = {value: {} for value in values}\n",
    "display(dict_db_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve columns in tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "dict_col_in_table = deepcopy(dict_db_tables)\n",
    "for db in dict_db.keys():\n",
    "    for table in dict_db[db]:\n",
    "        cur = conn.cursor()\n",
    "        query = f\"SHOW COLUMNS FROM {db}.{table}\"\n",
    "        cur.execute(query)\n",
    "        result = cur.fetchall()\n",
    "        cur.close()\n",
    "        cols = [value[0] for value in result]\n",
    "        i=0\n",
    "        for i in range(len(cols)):\n",
    "            dict_col_in_table[db][table][cols[i]] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meteo1': {'DATA': {'utctimestamp': [], 'download': []},\n",
       "  'LOGBOOK': {'utctimestamp': [], 'event': []},\n",
       "  'ane0': {'utctimestamp': [], 'windspeed': [], 'winddirection': []},\n",
       "  'bar0': {'utctimestamp': [], 'atmosphericpressure': []},\n",
       "  'cpr0': {'utctimestamp': [],\n",
       "   'uptime': [],\n",
       "   'diskspace': [],\n",
       "   'ramusage': [],\n",
       "   'runningprocesses': [],\n",
       "   'cpuload': []},\n",
       "  'gps0': {'utctimestamp': [],\n",
       "   'latitude': [],\n",
       "   'longitude': [],\n",
       "   'satellites': [],\n",
       "   'hdop': [],\n",
       "   'altitude': []},\n",
       "  'gsm0': {'utctimestamp': [], 'atstatus': [], 'smsstatus': []},\n",
       "  'ntp0': {'utctimestamp': [], 'offset': []},\n",
       "  'rad0': {'utctimestamp': [], 'parirradiance': []},\n",
       "  'the0': {'utctimestamp': [], 'airtemperature': []}},\n",
       " 'mouleconnected': {'Temperature': {'IdBac': [], 'IdTemperature': []},\n",
       "  'bac': {'Description': [], 'IdBac': []},\n",
       "  'capteur': {'UniteMesure': [],\n",
       "   'IdMoule': [],\n",
       "   'IdTemperature': [],\n",
       "   'IdLumiere': [],\n",
       "   'IdBac': [],\n",
       "   'IdCapteur': []},\n",
       "  'data': {'DateMesure': [],\n",
       "   'IdCapteur': [],\n",
       "   'ValMesure': [],\n",
       "   'ConvTimeStamp': [],\n",
       "   'IdData': []},\n",
       "  'data2': {'DateMesure': [],\n",
       "   'IdCapteur': [],\n",
       "   'ValMesure': [],\n",
       "   'ConvTimeStamp': [],\n",
       "   'IdData': []},\n",
       "  'lumiere': {'IdBac': [], 'IdLumiere': []},\n",
       "  'moule': {'IdBac': [], 'IdMoule': []},\n",
       "  'users': {'Id': [], 'Pseudo': [], 'Password': []}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_col_in_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meteo1': {'DATA': {},\n",
       "  'LOGBOOK': {},\n",
       "  'ane0': {},\n",
       "  'bar0': {},\n",
       "  'cpr0': {},\n",
       "  'gps0': {},\n",
       "  'gsm0': {},\n",
       "  'ntp0': {},\n",
       "  'rad0': {},\n",
       "  'the0': {}},\n",
       " 'mouleconnected': {'Temperature': {},\n",
       "  'bac': {},\n",
       "  'capteur': {},\n",
       "  'data': {},\n",
       "  'data2': {},\n",
       "  'lumiere': {},\n",
       "  'moule': {},\n",
       "  'users': {}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_db_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#? get columns inside each tables and store it inside a dictionnary with arrays as values\n",
    "# for db in dict_db.keys():\n",
    "#     for table in dict_db[db]:\n",
    "#         cur = conn.cursor()\n",
    "#         query = f\"SHOW COLUMNS FROM {db}.{table}\"\n",
    "#         cur.execute(query)\n",
    "#         result = cur.fetchall()\n",
    "#         cols = [value[0] for value in result]\n",
    "#         i=0\n",
    "#         for i in range(len(cols)):\n",
    "#             dict_db_tables[db][table][cols[i]] = []\n",
    "\n",
    "# display(dict_db_tables)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from table and insert it in the right column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for db in dict_db.keys(): # iteration selon les bdd\n",
    "#     for table in dict_db[db]: # pour chaque tables de chaque BDD\n",
    "#         cur = conn.cursor()\n",
    "#         query = f\"SELECT * FROM {db}.{table}\" # extraction de l'intégralité des données\n",
    "#         cur.execute(query)\n",
    "#         result = cur.fetchall()\n",
    "#         rowNb = 0\n",
    "#         columnNb = 0\n",
    "#         for col in dict_db_tables[db][table]: # pour chaque colonne dans la table\n",
    "#             for rowNb in range(len(result)): # pour chaque ligne dnas la table\n",
    "#                 dict_db_tables[db][table][col].append(result[rowNb][columnNb]) # on ajoute à la liste la donnée de la ligne correspondant à la colonne actuelle\n",
    "#             columnNb+=1 # on passe à la colonne suivante\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a dictionnary containing all the databases ; with their tables ; column inside tables and finaly all values per columns like this : \n",
    "<pre>\n",
    "<code>\n",
    "{\n",
    "    database1 : {\n",
    "        table1 : {\n",
    "            column1 : [value1,value2, ..., valueN],\n",
    "            column2 : [value1,value2, ..., valueM],\n",
    "            ...\n",
    "        },\n",
    "        table2 : {\n",
    "            column1 : [value1,value2, ..., valueN],\n",
    "            column2 : [value1,value2, ..., valueM],\n",
    "            ...\n",
    "        },\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "</code>\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For databases that contain timestamp with value in each tables like meteo1 we can directly insert data from each tables into Elastic because the data will be studied 'separetely'.\n",
    "For database with relation between tables like mouleconnected we have to join tables</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define list of databases that requires to join tables and which that doesn't need to there tables to be joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_db_nojoin = ['meteo1']\n",
    "list_db_withjoin = [ x for x in dbs_list if x not in list_db_nojoin] # from the list containing all databases we retrieve only db that are not those that do not require join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction for database with disjoined tables with utctimestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! TODO create two lists of databases, one for db with disjoined tables ; one db with tables to join \n",
    "for db in list_db_nojoin:\n",
    "    for table in dict_db[db]: # pour chaque tables de chaque BDD\n",
    "        cur = conn.cursor()\n",
    "        query = f\"SELECT * FROM {db}.{table} ORDER BY utctimestamp ASC \" # extraction de l'intégralité des données\n",
    "        cur.execute(query)\n",
    "        result = cur.fetchall()\n",
    "        cur.close()\n",
    "        rowNb = 0\n",
    "        for rowNb in range(len(result)): # pour chaque ligne dans la table\n",
    "            item = f'item_{rowNb}'\n",
    "            dict_db_tables[db][table][item] = {}\n",
    "            columnNb = 0\n",
    "            for col in dict_col_in_table[db][table]: # pour chaque colonne dans la table\n",
    "                dict_db_tables[db][table][item][col] = result[rowNb][columnNb] # on ajoute à la liste la donnée de la ligne correspondant à la colonne actuelle\n",
    "                columnNb+=1 # on passe à la colonne suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utctimestamp': 20121218081745, 'windspeed': 11.3, 'winddirection': 264.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_db_tables['meteo1']['ane0']['item_14713880']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data from databases that do not require join in ndjson format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a directory per db and a file per table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a batch_size\n",
    "def select_batch_size(n):\n",
    "    diviseurs = []\n",
    "    for i in range(20, 500000):\n",
    "        if n % i == 0:\n",
    "            diviseurs.append(i)\n",
    "            print(i)\n",
    "    return random.choice(diviseurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97499\n",
      "194998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97499"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_batch_size(194998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui convertit les nan en None car les nan ne sont pas supportés en json\n",
    "def nan_serializer(obj):\n",
    "        if pd.isna(obj):\n",
    "                return None\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_dir = os.getcwd()\n",
    "for db in list_db_nojoin:\n",
    "    folder_path = current_dir + '/' + db\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    for table in dict_db_tables[db] :\n",
    "        file_path = f'{db}/{table}.ndjson'\n",
    "        lenght = len(dict_db_tables[db][table].items())\n",
    "        if lenght <= 500000:\n",
    "            for key, value in dict_db_tables[db][table].items():\n",
    "                with open(file_path, 'a') as f:\n",
    "                    f.write(json.dumps({key:value}) + '\\n')\n",
    "        else :\n",
    "            batch_size = select_batch_size(lenght)\n",
    "            # on crée une liste contenant chacun des éléments du dictionnaire afin de pouvoir les parcourir \n",
    "            items = list(dict_db_tables[db][table].items())\n",
    "            batches = [items[i:i+batch_size] for i in range(0,lenght, batch_size)]\n",
    "            # on parcourt les lots\n",
    "            for i, batch in enumerate(batches):\n",
    "                # on enregistre le contenu du lot dans un fichier\n",
    "                with open(file_path, 'a') as f:\n",
    "                    for key, value in batch:\n",
    "                        entry = {key:value}\n",
    "                        f.write(json.dumps(entry, default=nan_serializer) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining tables for databases with relation between tables beyond timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the data from all useful tables in mouleconnected database, store it into dataframe stored in a dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = {}\n",
    "for db in list_db_withjoin:\n",
    "    df_list[db]={}\n",
    "    for table in dict_db[db]:\n",
    "        if db == 'mouleconnected':\n",
    "            if table in ['data', 'data2', 'capteur', 'bac']:\n",
    "                cur = conn.cursor()\n",
    "                query = f\"SELECT * FROM {db}.{table}\"\n",
    "                cur.execute(query)\n",
    "                result = cur.fetchall()\n",
    "                columns = [col for col in dict_col_in_table[db][table].keys()]\n",
    "                cur.close()\n",
    "                if (table == 'data' or table =='data2'):\n",
    "                    df = pd.DataFrame(result, columns=columns, dtype=pd.Int64Dtype())\n",
    "                elif table == \"capteur\":\n",
    "                    df = pd.DataFrame(result, columns=columns).astype({'UniteMesure':str, 'IdMoule': pd.Int64Dtype(), 'IdTemperature': pd.Int64Dtype(), 'IdLumiere': pd.Int64Dtype(), 'IdCapteur':pd.Int64Dtype(), 'IdBac': pd.Int64Dtype()})\n",
    "                else:\n",
    "                    df = pd.DataFrame(result, columns=columns).astype({'IdBac': int, 'Description': str}) \n",
    "                df_list[db][table] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateMesure</th>\n",
       "      <th>IdCapteur</th>\n",
       "      <th>ValMesure</th>\n",
       "      <th>ConvTimeStamp</th>\n",
       "      <th>IdData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200825141815</td>\n",
       "      <td>1</td>\n",
       "      <td>2557</td>\n",
       "      <td>1598365095000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200825141815</td>\n",
       "      <td>2</td>\n",
       "      <td>2833</td>\n",
       "      <td>1598365095000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200825141815</td>\n",
       "      <td>3</td>\n",
       "      <td>3032</td>\n",
       "      <td>1598365095000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200825141815</td>\n",
       "      <td>4</td>\n",
       "      <td>2765</td>\n",
       "      <td>1598365095000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200825141815</td>\n",
       "      <td>5</td>\n",
       "      <td>2361</td>\n",
       "      <td>1598365095000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24519043</th>\n",
       "      <td>20200907090210</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1599469329000</td>\n",
       "      <td>24519044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24519044</th>\n",
       "      <td>20200907090210</td>\n",
       "      <td>201</td>\n",
       "      <td>1750</td>\n",
       "      <td>1599469329000</td>\n",
       "      <td>24519045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24519045</th>\n",
       "      <td>20200907090210</td>\n",
       "      <td>202</td>\n",
       "      <td>1725</td>\n",
       "      <td>1599469329000</td>\n",
       "      <td>24519046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24519046</th>\n",
       "      <td>20200907090210</td>\n",
       "      <td>203</td>\n",
       "      <td>-6</td>\n",
       "      <td>1599469329000</td>\n",
       "      <td>24519047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24519047</th>\n",
       "      <td>20200907090210</td>\n",
       "      <td>204</td>\n",
       "      <td>-6</td>\n",
       "      <td>1599469329000</td>\n",
       "      <td>24519048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24519048 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DateMesure  IdCapteur  ValMesure  ConvTimeStamp    IdData\n",
       "0         20200825141815          1       2557  1598365095000         1\n",
       "1         20200825141815          2       2833  1598365095000         2\n",
       "2         20200825141815          3       3032  1598365095000         3\n",
       "3         20200825141815          4       2765  1598365095000         4\n",
       "4         20200825141815          5       2361  1598365095000         5\n",
       "...                  ...        ...        ...            ...       ...\n",
       "24519043  20200907090210        104          0  1599469329000  24519044\n",
       "24519044  20200907090210        201       1750  1599469329000  24519045\n",
       "24519045  20200907090210        202       1725  1599469329000  24519046\n",
       "24519046  20200907090210        203         -6  1599469329000  24519047\n",
       "24519047  20200907090210        204         -6  1599469329000  24519048\n",
       "\n",
       "[24519048 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list['mouleconnected']['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join tables of mouleconnected db into a unique dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_mouleconnected():\n",
    "    # drop unused column from tables\n",
    "    if 'IdData' in df_list['mouleconnected']['data']:\n",
    "        data = df_list['mouleconnected']['data'].drop(['IdData', 'DateMesure'], axis=1)\n",
    "        data2 = df_list['mouleconnected']['data2'].drop(['IdData', 'DateMesure'], axis=1)\n",
    "    else :\n",
    "        data = df_list['mouleconnected']['data']\n",
    "        data2 = df_list['mouleconnected']['data2']\n",
    "\n",
    "    capteur = df_list['mouleconnected']['capteur']\n",
    "    bac = df_list['mouleconnected']['bac']\n",
    "    # concatenate the content of data and data2\n",
    "    data_df = pd.concat([data, data2], ignore_index=True)\n",
    "\n",
    "    # join data_df with capteur\n",
    "    data_df = pd.merge(data_df, capteur, on='IdCapteur', how='right')\n",
    "    # join data_df with bac\n",
    "    data_df = pd.merge(data_df, bac, on='IdBac', how='right')\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the dataframe into json for easy insertion in ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = join_mouleconnected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdCapteur</th>\n",
       "      <th>ValMesure</th>\n",
       "      <th>ConvTimeStamp</th>\n",
       "      <th>UniteMesure</th>\n",
       "      <th>IdMoule</th>\n",
       "      <th>IdTemperature</th>\n",
       "      <th>IdLumiere</th>\n",
       "      <th>IdBac</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2044066</th>\n",
       "      <td>2</td>\n",
       "      <td>2284</td>\n",
       "      <td>1618423247000</td>\n",
       "      <td>Volt</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375116</th>\n",
       "      <td>103</td>\n",
       "      <td>178</td>\n",
       "      <td>1618423247000</td>\n",
       "      <td>Volt</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22485466</th>\n",
       "      <td>16</td>\n",
       "      <td>2276</td>\n",
       "      <td>1618423247000</td>\n",
       "      <td>Volt</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021996</th>\n",
       "      <td>1</td>\n",
       "      <td>2282</td>\n",
       "      <td>1618423247000</td>\n",
       "      <td>Volt</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11242696</th>\n",
       "      <td>102</td>\n",
       "      <td>1713</td>\n",
       "      <td>1618423247000</td>\n",
       "      <td>Volt</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;br /&gt;kjihih</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IdCapteur  ValMesure  ConvTimeStamp UniteMesure  IdMoule  \\\n",
       "2044066           2       2284  1618423247000        Volt        2   \n",
       "17375116        103        178  1618423247000        Volt     <NA>   \n",
       "22485466         16       2276  1618423247000        Volt       16   \n",
       "1021996           1       2282  1618423247000        Volt        1   \n",
       "11242696        102       1713  1618423247000        Volt     <NA>   \n",
       "\n",
       "          IdTemperature  IdLumiere  IdBac    Description  \n",
       "2044066            <NA>       <NA>      1           test  \n",
       "17375116           <NA>        103      3           Test  \n",
       "22485466           <NA>       <NA>      4                 \n",
       "1021996            <NA>       <NA>      1           test  \n",
       "11242696           <NA>        102      2   <br />kjihih  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24529682 entries, 2044066 to 24529681\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   IdCapteur      Int64 \n",
      " 1   ValMesure      Int64 \n",
      " 2   ConvTimeStamp  Int64 \n",
      " 3   UniteMesure    object\n",
      " 4   IdMoule        Int64 \n",
      " 5   IdTemperature  Int64 \n",
      " 6   IdLumiere      Int64 \n",
      " 7   IdBac          Int64 \n",
      " 8   Description    object\n",
      "dtypes: Int64(7), object(2)\n",
      "memory usage: 2.0+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.sort_values(by='ConvTimeStamp', ascending=False, inplace=True)\n",
    "display(test.head())\n",
    "display(test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Works but very long to compute (From 15 to 30minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouleconnected = {}\n",
    "i = 0\n",
    "mouleconnected['state'] = 0\n",
    "for index, row in test.iterrows():\n",
    "    if pd.notna(row['ConvTimeStamp']):\n",
    "        if row['ConvTimeStamp'] != mouleconnected['state']:\n",
    "            mouleconnected['state'] = row['ConvTimeStamp']\n",
    "            item = f'item_{i}'\n",
    "            i+=1\n",
    "            mouleconnected[item] = {}\n",
    "            mouleconnected[item]['timestamp'] = row['ConvTimeStamp']\n",
    "            mouleconnected[item]['records'] = {}\n",
    "            record_nb = 0\n",
    "        else:\n",
    "            record_nb += 1\n",
    "        record_value = f'record_{record_nb}'\n",
    "        mouleconnected[item]['records'][record_value]={}\n",
    "        for col, value in row.items():\n",
    "            if col != 'ConvTimeStamp':\n",
    "                mouleconnected[item]['records'][record_value][col] = value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1022014"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mouleconnected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# on crée une liste contenant chacun des éléments du dictionnaire afin de pouvoir les parcourir \n",
    "items = list(mouleconnected.items())\n",
    "\n",
    "# on crée des lots de 74 éléments du dictionnaire\n",
    "batches = [items[i:i+74] for i in range(1,len(mouleconnected), 74)]\n",
    "\n",
    "# on parcourt les lots\n",
    "for i, batch in enumerate(batches):\n",
    "    # on enregistre le contenu du lot dans un fichier\n",
    "    with open('mouleconnected.ndjson', 'a') as f:\n",
    "        for key, value in batch:\n",
    "            entry = {key:value}\n",
    "            f.write(json.dumps(entry, default=nan_serializer) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative en cours pour réalister la même chose mais en plusieurs étapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouleconnectedBatch = {}\n",
    "# i = 0\n",
    "# mouleconnected['state'] = 0\n",
    "# for group_key, group_chunk in test.groupby(by='ConvTimeStamp'):\n",
    "#     print(group_key, group_chunk)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
