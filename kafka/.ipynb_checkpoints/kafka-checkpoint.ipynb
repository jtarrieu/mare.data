{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "689fb7ae-904a-4992-b666-061d1074551c",
   "metadata": {},
   "source": [
    "# Kafka client tutorial\n",
    "Kafka allow you to create **topics**, and **produce** and **consume** message inside those topics.\n",
    "\n",
    "To do so we'll need too install the kafka-python library to allow us to connect to our kafka brokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d90ee2-42c3-462f-9aa3-9889b0f706ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kafka-python\n",
      "  Using cached kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
      "Installing collected packages: kafka-python\n",
      "Successfully installed kafka-python-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758f9d69-2c71-4f55-bec2-7b5df609a09f",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Here are some examples of configuration you can  override.\n",
    "\n",
    "| Configuration                     | Description                                                                                                                              | Example Values                                           |\r\n",
    "| --------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------- |\r\n",
    "| **Topic Name**                    | The name of the topic.                                                                                                                   | `my_topic`                                               |\r\n",
    "| **Number of Partitions**          | `num_partitions`: The number of partitions in the topic. Partitions allow for parallel processing of messages.                           | `3`, `5`, `10`                                           |\r\n",
    "| **Replication Factor**            | `replication_factor`: The number of replicas for each partition. Replicas provide fault tolerance.                                       | `2`, `3`, `4`                                            |\r\n",
    "| **Retention Policy**              | `retention_ms` or `retention_bytes`: The retention period for messages in the topic.                                                     | `86400000` (milliseconds), `100000000` (bytes)           |\r\n",
    "| **Cleanup Policy**                | `cleanup.policy`: The policy to use for log retention. Options include \"delete\" or \"compact\" for compacted topics.                       | `delete`, `compact`                                      |\r\n",
    "| **Segment Size**                  | `segment.bytes`: The maximum size of a log segment file for the topic.                                                                   | `1073741824` (1 GB), `536870912` (512 MB)                |\r\n",
    "| **Segment Index Size**            | `segment.index.bytes`: The maximum size of an index file for the topic.                                                                  | `1048576` (1 MB), `524288` (512 KB)                      |\r\n",
    "| **Min In-Sync Replicas**          | `min.insync.replicas`: The minimum number of in-sync replicas required for a producer to consider a write complete.                      | `1`, `2`                                                 |\r\n",
    "| **Compression Type**              | `compression.type`: The compression type for the topic, such as \"gzip\", \"snappy\", or \"lz4\".                                              | `gzip`, `snappy`, `lz4`                                  |\r\n",
    "| **Message Format Version**        | `message.format.version`: The version of the message format for the topic.                                                               | `0.8.2`, `1.0`, `2.8`                                    |\r\n",
    "| **Unclean Leader Election**       | `unclean.leader.election.enable`: Whether unclean leader election is allowed.                                                            | `true`, `false`                                          |\r\n",
    "| **Auto Creation**                 | `auto.create.topics.enable`: Whether topics are automatically created on the server when a client makes a request with an unknown topic. | `true`, `false`                                          |\r\n",
    "| **Key Serializer**                | `key.serializer`: The serializer for message keys.                                                                                       | `org.apache.kafka.common.serialization.StringSerializer` |\r\n",
    "| **Value Serializer**              | `value.serializer`: The serializer for message values.                                                                    | `org.apache.kafka.common.serialization.StringSerializer` |ializaes needed     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b9464e-f608-47a0-82f5-12eeadfe4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka configuration\n",
    "\n",
    "kafka_config = {\n",
    "    'bootstrap_servers': 'kafka:19092',\n",
    "    'key_serializer': 'org.apache.kafka.common.serialization.StringSerializer',\n",
    "    'value_serializer': 'org.apache.kafka.common.serialization.StringSerializer',\n",
    "    'topic': 'topic-001',\n",
    "    'num_partitions': 1,\n",
    "    'replication_factor': 1,\n",
    "    'auto_offset_reset': 'earliest',\n",
    "    'auto.create.topics.enable': False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89686e3-7ba0-4bd6-a2aa-cc2ec16d5b25",
   "metadata": {},
   "source": [
    "## Create a topic\n",
    "Creatig a topic isn't necessary if the ***auto.create.topics.enable*** setting is True. You can directly write inside it and it will automatically create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0790c824-6c7e-4e99-8ed6-8d67c8462f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Topic name:  test\n"
     ]
    },
    {
     "ename": "TopicAlreadyExistsError",
     "evalue": "[Error 36] TopicAlreadyExistsError: Request 'CreateTopicsRequest_v3(create_topic_requests=[(topic='test', num_partitions=1, replication_factor=1, replica_assignment=[], configs=[])], timeout=30000, validate_only=False)' failed with response 'CreateTopicsResponse_v3(throttle_time_ms=0, topic_errors=[(topic='test', error_code=36, error_message=\"Topic 'test' already exists.\")])'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTopicAlreadyExistsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m new_topic \u001b[38;5;241m=\u001b[39m NewTopic(name               \u001b[38;5;241m=\u001b[39m name, \u001b[38;5;66;03m# kafka_config['topic'],\u001b[39;00m\n\u001b[1;32m     10\u001b[0m                      num_partitions     \u001b[38;5;241m=\u001b[39m kafka_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_partitions\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     11\u001b[0m                      replication_factor \u001b[38;5;241m=\u001b[39m kafka_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplication_factor\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Create the topic\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43madmin_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnew_topic\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreated !\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Close the admin client\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/kafka/admin/client.py:461\u001b[0m, in \u001b[0;36mKafkaAdminClient.create_topics\u001b[0;34m(self, new_topics, timeout_ms, validate_only)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupport for CreateTopics v\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m has not yet been added to KafkaAdminClient.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;241m.\u001b[39mformat(version))\n\u001b[1;32m    459\u001b[0m \u001b[38;5;66;03m# TODO convert structs to a more pythonic interface\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# TODO raise exceptions if errors\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request_to_controller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/kafka/admin/client.py:407\u001b[0m, in \u001b[0;36mKafkaAdminClient._send_request_to_controller\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m error_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Errors\u001b[38;5;241m.\u001b[39mNoError:\n\u001b[0;32m--> 407\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m error_type(\n\u001b[1;32m    408\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m failed with response \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m             \u001b[38;5;241m.\u001b[39mformat(request, response))\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mTopicAlreadyExistsError\u001b[0m: [Error 36] TopicAlreadyExistsError: Request 'CreateTopicsRequest_v3(create_topic_requests=[(topic='test', num_partitions=1, replication_factor=1, replica_assignment=[], configs=[])], timeout=30000, validate_only=False)' failed with response 'CreateTopicsResponse_v3(throttle_time_ms=0, topic_errors=[(topic='test', error_code=36, error_message=\"Topic 'test' already exists.\")])'."
     ]
    }
   ],
   "source": [
    "from kafka.admin import KafkaAdminClient, NewTopic\n",
    "\n",
    "# Set up the Kafka admin client with the Kafka broker address\n",
    "admin_client = KafkaAdminClient(bootstrap_servers=kafka_config['bootstrap_servers'])\n",
    "\n",
    "name = input('Topic name: ')\n",
    "\n",
    "# Create a NewTopic instance with the desired topic configuration\n",
    "new_topic = NewTopic(name               = name, # kafka_config['topic'],\n",
    "                     num_partitions     = kafka_config['num_partitions'],\n",
    "                     replication_factor = kafka_config['replication_factor'])\n",
    "\n",
    "# Create the topic\n",
    "admin_client.create_topics(new_topics=[new_topic])\n",
    "print('Created !')\n",
    "\n",
    "# Close the admin client\n",
    "admin_client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d4be3f-5b5e-4fc7-aa20-4bab4e82f998",
   "metadata": {},
   "source": [
    "## Produce message in a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8adf376-fd34-4460-b969-ea0b369de605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "from kafka.errors import KafkaError\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers=[kafka_config['bootstrap_servers']])\n",
    "\n",
    "topic = input('topic: ')\n",
    "message = input('message: ').encode()\n",
    "\n",
    "# Asynchronous by default\n",
    "future = producer.send(topic, message)\n",
    "\n",
    "# Block for 'synchronous' sends\n",
    "try:\n",
    "    record_metadata = future.get(timeout=10)\n",
    "    print('Message sent successfully.')\n",
    "except KafkaError as e:\n",
    "    # Decide what to do if produce request failed...\n",
    "    print(e)\n",
    "    pass\n",
    "\n",
    "# Successful result returns assigned partition and offset\n",
    "print(f'partition: {record_metadata.partition}')\n",
    "print(f'offset: {record_metadata.offset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f7d5ac-7670-4753-809c-7d9009e5ffd8",
   "metadata": {},
   "source": [
    "## Consume message from a topic\n",
    "Choose a topic to listen, it will list the messages it contains.\n",
    "Set the **auto_offset_reset** to **earliest** to see previous messages and to **latest** to only see the message in real-time.\n",
    ">Stop the kernel to quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a4f97-da48-46f4-a757-2354c4313133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "topic:  meteo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top:meteo, part:0, off:4529: key=None value=b'{\"timestamp\": \"2024-01-16 13:35:20.138322\", \"temperature\": 20.32, \"humidity\": 40.3, \"pressure\": 1004.34, \"sensor_id\": 1, \"location\": {\"lon\": 3.18298, \"lat\": 42.471203}}'''"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top:meteo, part:0, off:32103: key=None value=b'{\"timestamp\": \"2024-01-16 17:25:41.428047\", \"temperature\": 27.07, \"humidity\": 59.65, \"pressure\": 1009.64, \"sensor_id\": 2, \"location\": {\"lon\": 3.184122, \"lat\": 42.473493}}'\r"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "topic = input('topic: ')\n",
    "\n",
    "# To consume latest messages and auto-commit offsets\n",
    "consumer = KafkaConsumer(topic,\n",
    "                         bootstrap_servers  = [kafka_config['bootstrap_servers']],\n",
    "                         auto_offset_reset  = kafka_config['auto_offset_reset'],\n",
    "                        enable_auto_commit = True)\n",
    "for message in consumer:\n",
    "    # message value and key are raw bytes -- decode if necessary!\n",
    "    # e.g., for unicode: `message.value.decode('utf-8')`\n",
    "    print (\"top:%s, part:%d, off:%d: key=%s value=%s\" % (message.topic, message.partition,\n",
    "                                          message.offset, message.key,\n",
    "                                          message.value),\n",
    "          end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45920b4f-79b8-4b16-b6e2-a1325d0b9dd0",
   "metadata": {},
   "source": [
    "## List topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb047f8-131d-41c4-bd03-f2cf128eeb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meteo\n",
      "docker-connect-status\n",
      "__consumer_offsets\n",
      "docker-connect-offsets\n",
      "docker-connect-configs\n"
     ]
    }
   ],
   "source": [
    "from kafka.admin import KafkaAdminClient\n",
    "\n",
    "# Set up the Kafka admin client with the Kafka broker address\n",
    "admin_client = KafkaAdminClient(bootstrap_servers=kafka_config['bootstrap_servers'])\n",
    "\n",
    "# List all the topic names in the cluster\n",
    "topic_names = admin_client.list_topics()\n",
    "\n",
    "# Print the list of topic names\n",
    "for topic_name in topic_names:\n",
    "    print(topic_name)\n",
    "\n",
    "# Close the admin client\n",
    "admin_client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f1e2db-9a87-472e-88f7-6d31dd162623",
   "metadata": {},
   "source": [
    "## Delete a topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e08b7a-0e17-49ed-b4d5-6f8a6666b429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Topic name:  meteo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic deleted.\n"
     ]
    }
   ],
   "source": [
    "from kafka.admin import KafkaAdminClient\n",
    "from kafka.errors import KafkaError\n",
    "\n",
    "# Set up the Kafka admin client with the Kafka broker address\n",
    "admin_client = KafkaAdminClient(bootstrap_servers=kafka_config['bootstrap_servers'])\n",
    "\n",
    "# Define the name of the topic you want to delete\n",
    "topic_name = input('Topic name: ')\n",
    "\n",
    "# Attempt to delete the topic\n",
    "try:\n",
    "    admin_client.delete_topics(topics=[topic_name])\n",
    "    print('Topic deleted.')\n",
    "except KafkaError:\n",
    "    # Handle the case when the topic is already marked for deletion\n",
    "    print(f\"Topic '{topic_name}' is already marked for deletion.\")\n",
    "except Exception as e:\n",
    "    # Handle other exceptions if necessary\n",
    "    print(f\"An error occurred while deleting the topic: {e}\")\n",
    "\n",
    "# Close the admin client\n",
    "admin_client.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
